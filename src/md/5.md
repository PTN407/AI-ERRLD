### Các link
+ Trang Documentation: https://segmentation-models.readthedocs.io/en/latest/index.html
+ Dự án mẫu segmentation mèo: [Meow Segmentation](/src/ipynb/Mewo_Segmentation.ipynb)
### Hướng dẫn chi tiết của dự án:

#### Bước lấy dữ liệu
```python
import fiftyone as fo
import fiftyone.zoo as foz
```
  
Thư viện fiftyone giúp chúng ta lấy được bộ data open-image, đây là bộ (Chi tiết về bộ data và cách lấy [ở đây](https://github.com/PTN407/Notes/blob/main/src/md/2.md#:~:text=https%3A//storage.googleapis.com/openimages/web/index.html%20(Bonus%3A%20How%20to%20get%20this%20data%20on%20colab%3A%20https%3A//colab.research.google.com/github/voxel51/fiftyone/blob/v0.14.3/docs/source/tutorials/open_images.ipynb%23scrollTo%3DSCLf0GqBDsAJ) ))  
  
```python
dataset1 = foz.load_zoo_dataset(
    "open-images-v6",
    label_types = ['segmentations'],   # chỉ lấy bộ dữ liệu segmentations
    classes=['Cat'],                   # chỉ lấy những ảnh có nhãn là mèo
    max_samples=1000,                  # lấy 1000 ảnh, trong trường hợp trong bộ dữ liệu có < 1000 ảnh thỏa mãn thì sẽ lấy tất cả ảnh thỏa mãn 
    overwrite=True,
    seed=24,
    shuffle=True,
    dataset_name = "meowmeowdata1"
)
```

Đây là câu lệnh để lấy bộ data sementation mèo, chi tiết đã có ở link trên

#### Bước xử lí dữ liệu
```python
dataset1.first()
'''
Output:
<Sample: {
    'id': '61fcdc6846aff3227dc3788e',
    'media_type': 'image',
    'filepath': '/root/fiftyone/open-images-v6/validation/data/2e4831cdf0b4ce1e.jpg',
    'tags': BaseList(['validation']),
    'metadata': None,
    'segmentations': <Detections: {
        'detections': BaseList([
            <Detection: {
                'id': '61fcdc6846aff3227dc3788d',
                'attributes': BaseDict({}),
                'tags': BaseList([]),
                'label': 'Cat',
                'bounding_box': BaseList([0.0, 0.0, 1.0, 1.0]),
                'mask': array([[False, False, False, ..., False, False, False],
                       [False, False, False, ..., False, False, False],
                       [False, False, False, ..., False, False, False],
                       ...,
                       [False, False, False, ..., False, False, False],
                       [False, False, False, ..., False, False, False],
                       [False, False, False, ..., False, False, False]]),
                'confidence': None,
                'index': None,
            }>,
        ]),
    }>,
    'open_images_id': '2e4831cdf0b4ce1e',
}>
'''
```

Đây là câu lệnh để in ra các đặc điểm chứa trong một biến data, có những đặc điểm sau cần lưu ý:
+ filepath: Là đường dẫn tới file ảnh, sau ta sẽ dùng đường dẫn này để đọc ảnh.
+ label: Nhãn của ảnh, thông tin này sẽ có ích trong một số bài toán, ví dụ như bài toán phân loại, nhưng ta đang trong bài toán segmentation nên thông tin này không có ích lắm.
+ bounding_box: như tên gọi, là tọa độ bounding box của vật trong ảnh, 4 số này lần lượt là: hoành độ, tung độ, chiều dài, chiều cao, tính tỉ lệ so với độ dài chiều tương ứng của ảnh, như vậy, hoành độ thật của ảnh là bounding_box[0] * img.shape[1], tung độ thật là bounding_box[1] * img.shape[0], ...
+ mask: một mảng đánh dấu xem trong bounding box, những pixel nào là mèo (True) và không phải mèo (False).
+ confidence: độ tự tin với vật trong ảnh, thông tin này sẽ có ích trong một số bài toán nhưng không có ích ở đây

```python
# get image, mask, bounding box from data
img = cv2.imread(data['filepath'])                                      # đọc ảnh từ filepath
mask = data['segmentations']['detections'][0]['mask']                   # đọc mask từ data
bounding_box = data['segmentations']['detections'][0]['bounding_box']   # đọc bounding box
```
```python
# đưa ảnh về kích thước sao cho kích thước của bounding_box trùng với kích thước của mask
w = round(bounding_box[2] * img.shape[1])
h = round(bounding_box[3] * img.shape[0])
img = imutils.resize(img, width = round(mask.shape[1] / (bounding_box[2] * img.shape[1]) * img.shape[1] + 2))
```
```python
# cut image to bounding box
x = int(bounding_box[0] * img.shape[1])
y = int(bounding_box[1] * img.shape[0])
img = img[y:y+mask.shape[0], x:x+mask.shape[1]].copy()
# cắt ảnh theo bounding box
```
```python
# Đưa tất cả các ảnh về cùng kích thước để dễ huấn luyện mô hình
SIZE = (256, 256)                                                             # kích thước cần đưa về
masked_img = img.copy()                                                       # masked_img có tác dụng chỉ giữ lại những pixel chứa mèo
masked_img[~mask] = [0, 0, 0]                                                 # bôi đen những pixel không chứa mèo
masked_img = cv2.resize(masked_img, SIZE, interpolation=cv2.INTER_CUBIC)      # chỉnh kích thước ảnh mask về SIZE
img = cv2.resize(img, SIZE, interpolation=cv2.INTER_CUBIC)                    # chỉnh kích thước ảnh
mask = np.zeros((SIZE[0],SIZE[1],1), np.uint8)                                # mask ở đây có tác dụng như mask ở data, nhưng đã đưa về kích thước SIZE để dễ xử lí, ban đầu là ảnh đen, sau đó
mask[np.nonzero(cv2.cvtColor(masked_img,cv2.COLOR_BGR2GRAY))] = 1             # đánh dấu những pixel chứa mèo là 1
```

#### huấn luyện mô hình
```python
BACKBONE = 'resnet34'
preprocess_input = sm.get_preprocessing(BACKBONE) 
```

Backbone là phần mạng dùng để tách feature ra khỏi ảnh, trong trường này là CNN, có nhiều loại CNN khác nhau được hỗ trợ trong thư viện:  
  

![image](https://user-images.githubusercontent.com/92132592/152690594-da9d4ada-94ad-452f-abdf-5e59ad1f3743.png)  
 <p style="text-align: center;">  (source: https://github.com/qubvel/segmentation_models)  </p>
 
 
 ```python
sm.set_framework('tf.keras')                                # sử dụng framework là keras để train
sm.framework()
model = sm.Linknet(BACKBONE, encoder_weights='imagenet')    # Sử dụng mô hình Linknet để train ( các mô hình có sẵn bao gồm Unet, FPN, Linknet, PSPNet)
model.compile(
    'Adam',                                                 # Adam là một optimizer rất hiệu quả trong nhiều bài toán, trong đó có segmentation
    loss=sm.losses.bce_jaccard_loss,                        # Một loss function hiệu quả trong bài toán segmentation
    metrics=[sm.metrics.iou_score],                         # đánh giá hiệu quả mô hình
)
```

```python
model.fit(
   x=x,
   y=y,
   batch_size=16,
   epochs=300,
   validation_data=(x_val, y_val),
)
# fit mô hình
```

#### Kết quả
Sau khi train ta chạy thử và minh họa trên một vài ảnh ở trong validation:  
![image](https://user-images.githubusercontent.com/92132592/152690927-8afd419c-6eaa-467b-8087-83c1dbb3d1c2.png)




